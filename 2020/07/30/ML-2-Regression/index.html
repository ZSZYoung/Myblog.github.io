<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Aozy"><title>ML-2-Regression · Aozy</title><meta name="description" content="Case(預測寶可夢進化後CP值)第一步是尋找func set(model)，這邊假設是線性func
第二步是設計loss function以評訓練過程中得到的func的好壞Loss Function:評估一個function的好壞，輸入為function，輸出為loss
第三步是尋找func se"><meta name="keywords" content="博客,运维,blog"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- 加入测试--><!--link (rel="icon", href= url_for('images/favicon.ico')) --><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">Aozy</a></h3><div class="description"><p>何如暮暮與朝朝，更改卻，年年歲歲。</p></div></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/ZSZYoung"><i class="fa fa-github"></i></a></li></ul><div class="footer"><div class="p"> <span>©  </span><i class="fa fa-star"></i><span> Aozy</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><a href="https://github.com/mrcore/hexo-theme-Anatole-Core" target="_blank">Anatole-Core  </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li><li><a href="/guestbook">留言</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>ML-2-Regression</a></h3></div><div class="post-content"><h1 id="Case-預測寶可夢進化後CP值"><a href="#Case-預測寶可夢進化後CP值" class="headerlink" title="Case(預測寶可夢進化後CP值)"></a>Case(預測寶可夢進化後CP值)</h1><p><img src="https://s1.ax1x.com/2020/07/30/anDWZR.png" alt="anDWZR.png"><br>第一步是尋找func set(model)，這邊假設是線性func</p>
<p><img src="https://s1.ax1x.com/2020/07/30/anycQS.png" alt="anycQS.png"><br>第二步是設計loss function以評訓練過程中得到的func的好壞<br><strong>Loss Function:評估一個function的好壞，輸入為function，輸出為loss</strong></p>
<p><img src="https://s1.ax1x.com/2020/07/30/an6vng.png" alt="an6vng.png"><br>第三步是尋找func set中最好的func，常用Gradient Descent(梯度下降法)</p>
<p>即尋找Lossfunction的全局最優解<br>梯度下降法結合對參數偏微分可以得到局部最優解，不一定取得全局最優解。<br><strong>在linear Regression中直接得到的就是全局最優解</strong><br>##梯度下降例子(對參數偏微分)<br><img src="https://s1.ax1x.com/2020/07/30/anRsKK.png" alt="anRsKK.png"></p>
<hr>
<h1 id="model-selection"><a href="#model-selection" class="headerlink" title="model selection"></a>model selection</h1><p>越發複雜的model往往越貼合training data，but not always lead to better performance on testing data(overfitting過度擬合)<br><img src="https://s1.ax1x.com/2020/07/30/anfr7D.png" alt="anfr7D.png"><br>此圖中三次的model是最好的，而不是更複雜的五次model</p>
<hr>
<h1 id="Regularization解決overfitting"><a href="#Regularization解決overfitting" class="headerlink" title="Regularization解決overfitting"></a>Regularization解決overfitting</h1><p>在原來的Loss Function中加上新的一項:<br><img src="https://s1.ax1x.com/2020/07/30/an7qdP.png" alt="an7qdP.png"><br>使得曲線趨於平滑以解決Overfitting的問題，這邊取的$\lambda$越大得到的曲線越發平滑，但過於平滑的曲線將無意義。故還是要尋找合適的$\lambda$值。<br><img src="https://s1.ax1x.com/2020/07/30/anHGWD.png" alt="anHGWD.png"></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2020-07-30</span><i class="fa fa-tag"></i><a class="tag" href="/tags/Machine-Learning/" title="Machine Learning">Machine Learning </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,http://aozy.tech/2020/07/30/ML-2-Regression/,Aozy,ML-2-Regression,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2021/01/25/github-hexo%E5%80%8B%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" title="Github+Hexo個人博客搭建">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2020/07/28/ML-1-introduction/" title="ML-1.introduction">下一篇</a></li></ul></div><script src="/js/visitors.js"></script><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@latest/dist/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:false|| false, 
  app_id:'LP5EBVNHfkmn17seVBnFrDIB-gzGzoHsz',
  app_key:'I1QAQGHsA6reNM2I3lwh3P8t',
  placeholder:'May the force be with you.',
  path: window.location.pathname,
  serverURLs: '',
  visitor:true,
  recordIP:true,
  avatar:'mp'
})</script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/baidu-tongji.js"></script></body></html>